{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5649d743",
   "metadata": {},
   "source": [
    "# Inference-time activation contrasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28959424",
   "metadata": {},
   "source": [
    "Data download: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36b6c790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stian\\ITU\\safetyneurons\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:18<00:00,  6.24s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.74s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the disk and cpu.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# model paths (update if different)\n",
    "path_base = \"./models/qwen3/Qwen3-4B\"               \n",
    "path_saferl = \"./models/qwen3/Qwen3-4B-SafeRL\"      \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(path_base, local_files_only=True)\n",
    "\n",
    "# Load both models\n",
    "model_base = AutoModelForCausalLM.from_pretrained(path_base, \n",
    "            dtype=torch.float16, \n",
    "            device_map=\"auto\",\n",
    "            local_files_only=True)\n",
    "\n",
    "model_saferl = AutoModelForCausalLM.from_pretrained(path_saferl, \n",
    "            dtype=torch.float16, \n",
    "            device_map=\"auto\", \n",
    "            local_files_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af5693c",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5a696350",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"Write me a poem about machine learning\"]    #can extend this to a list/dataset\n",
    "\n",
    "inputs = tokenizer(prompts, return_tensors=\"pt\").to(model_base.device)\n",
    "\n",
    "# dictionary for storing activations: \n",
    "activations_base = {}\n",
    "activations_saferl = {}\n",
    "\n",
    "\n",
    "def get_hook(store_dict, name):\n",
    "    def hook(module, input, output):\n",
    "        store_dict[name] = output.detach().float().cpu()\n",
    "    return hook\n",
    "\n",
    "# Pick the MLP layers\n",
    "nlayers = 7\n",
    "nlayers = min(nlayers, 36)      #ensures we stay within 36 (layers in LLM)\n",
    "for i in range(nlayers):        \n",
    "    \n",
    "    LAYER_INDEX = i \n",
    "\n",
    "\n",
    "    # layer = model.model.layers[LAYER_INDEX]\n",
    "    layer_base = model_base.model.layers[LAYER_INDEX]\n",
    "    layer_saferl = model_saferl.model.layers[LAYER_INDEX]\n",
    "\n",
    "    #only hooking MLP activations: \n",
    "    #layer.mlp.register_forward_hook(...)\n",
    "    hook_base = layer_base.register_forward_hook(get_hook(activations_base, f\"layer_{LAYER_INDEX}\"))\n",
    "    hook_saferl = layer_saferl.register_forward_hook(get_hook(activations_saferl, f\"layer_{LAYER_INDEX}\"))\n",
    "\n",
    "    # Forward pass - The inference\n",
    "\n",
    "    with torch.no_grad():           \n",
    "        _ = model_base(**inputs)        # _ ignoring output since we only care about activations. \n",
    "        _ = model_saferl(**inputs)      \n",
    "\n",
    "    # Remove hooks - important ot reset the hook per iterations (avoiding memory leaks)\n",
    "    hook_base.remove()\n",
    "    hook_saferl.remove()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368540b1",
   "metadata": {},
   "source": [
    "Exploring the data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "17b34118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basemodel layer shapes:\n",
      "\n",
      "torch.Size([1, 7, 2560])\n",
      "torch.Size([1, 7, 2560])\n",
      "\n",
      "Fine-tuned model layer shapes:\n",
      "\n",
      "torch.Size([1, 7, 2560])\n",
      "torch.Size([1, 7, 2560])\n"
     ]
    }
   ],
   "source": [
    "#verifying that the models have same shapes in the layers: \n",
    "print('Basemodel layer shapes:\\n')\n",
    "for i in range(nlayers):\n",
    "    print(activations_base[f'layer_{i}'].size())\n",
    "\n",
    "\n",
    "print('\\nFine-tuned model layer shapes:\\n')\n",
    "for i in range(nlayers): \n",
    "    print(activations_saferl[f'layer_{i}'].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c6ca606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0055)\n",
      "tensor(0.0055)\n"
     ]
    }
   ],
   "source": [
    "#the activations can be viewed as such: \n",
    "\n",
    "print(activations_base['layer_0'][0][6][1000])   #layers are 3D-tensors...\n",
    "print(activations_base['layer_0'].flatten()[6*2560+1000])     #which means they can be flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c63e545",
   "metadata": {},
   "source": [
    "Computing the RMSE, per neuron per layer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "11042aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.3750e+00, -1.9424e+00,  1.2559e+00,  ..., -3.3643e-01,\n",
       "         2.1576e-02,  4.3945e-03])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations_base[f'layer_{0}'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3b286da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.3398e+00, -1.9346e+00,  1.2539e+00,  ..., -3.3521e-01,\n",
       "         2.0386e-02,  4.8218e-03])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations_saferl['layer_0'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7febfb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0352, -0.0078,  0.0020,  ..., -0.0012,  0.0012, -0.0004])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations_base[f'layer_{0}'].flatten() - activations_saferl['layer_0'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "335950f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nlayers):\n",
    "    (activations_base[f'layer_{i}'].flatten() - activations_base[f'layer_{i}'].flatten())**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8fc287",
   "metadata": {},
   "source": [
    "We can actually sort the values of a flattened tensor: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "afab2b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.sort(\n",
      "values=tensor([-2.7969, -2.1777, -1.9346,  ...,  2.2246,  3.7852,  6.3398]),\n",
      "indices=tensor([  77,   10,    1,  ..., 2560, 5120,    0]))\n",
      "tensor([-2.7969, -2.1777, -1.9346,  ...,  2.2246,  3.7852,  6.3398])\n",
      "tensor([  77,   10,    1,  ..., 2560, 5120,    0])\n"
     ]
    }
   ],
   "source": [
    "print(activations_saferl['layer_0'].flatten().sort())\n",
    "\n",
    "#[0] gives values, [1] gives indices\n",
    "print(activations_saferl['layer_0'].flatten().sort()[0])\n",
    "print(activations_saferl['layer_0'].flatten().sort()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b55bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.7969, -2.1777, -1.9346,  ...,  2.2246,  3.7852,  6.3398])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations_saferl['layer_0'].flatten().sort()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a559884",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
