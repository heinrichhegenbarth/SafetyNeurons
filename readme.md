# This is the Github repo for the miniproject in AML4NLP

## Main Idea
Using the concept safety neurons (SN) to predict "unsafe" inputs to an LLM

### Safety Neurons
SN are the neurons that activate if an "unsafe" input is passed to an LLM

## Literature/ Reads
A Mechanistic Perspective from Safety Neurons 
| [Chen et al., 2025](https://arxiv.org/pdf/2406.14144)

### Githubs
- implementation chen paper: https://github.com/THU-KEG/SafetyNeuron.git

## Approach
1. Compare approaches from Literature
2. Find Small LLM and run Locally 
3. Use dataset with unsafe prompts to identify SN
    3.1. Visualize SN -> validate their existance
4. Train classifier on them to check output.
5. Scale up to larger LLM using HPC


## Which LLM to use. 


## LLama github repo
https://github.com/meta-llama


